# ğŸ§  PromptSense

**Context-Aware Prompt Personalization for Improved LLM Output Quality**

PromptSense is an intelligent system that dynamically personalizes prompts based on user intent, domain, preferences, and previous interaction history. It uses FAISS vector search to find similar past queries and leverages Postgres Neon for storing conversation history, resulting in more accurate, consistent, and user-aligned AI responses.

---

## ğŸŒŸ Features

- **Context-Aware Personalization**: Automatically enhances prompts with user context
- **Intent Detection**: Identifies user intent (learning, problem-solving, creative, etc.)
- **Domain Classification**: Detects topic domain (technology, science, business, etc.)
- **Vector Similarity Search**: Uses FAISS to find similar past queries
- **Conversation History**: Maintains context across interactions
- **User Preferences**: Adapts to expertise level and communication style
- **Modern Chat UI**: Clean, responsive interface
- **Real-time Analytics**: View insights about your interactions

---

## ğŸ—ï¸ Architecture

```
PromptSense System Flow:

User Message
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prompt Engine         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Detect Intent        â”‚
â”‚ 2. Detect Domain        â”‚
â”‚ 3. Get User Profile     â”‚
â”‚ 4. Get History          â”‚
â”‚ 5. Search Similar (FAISS)â”‚
â”‚ 6. Build Enhanced Promptâ”‚
â”‚ 7. Generate Response    â”‚
â”‚ 8. Save to DB + Vector  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Enhanced LLM Response
```

---

## ğŸ“‹ Prerequisites

- Python 3.9 or higher
- PostgreSQL database (Postgres Neon recommended)
- OpenAI API key
- pip (Python package manager)

---

## ğŸš€ Installation & Setup

### 1. Clone or Download the Project

```bash
cd "C:\Users\JARVIS\Desktop\Genai Project [Context Aware prompt tuning]"
```

### 2. Create Virtual Environment

```bash
python -m venv venv

# Activate on Windows:
venv\Scripts\activate

# Activate on macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up Postgres Neon Database

1. Go to [Neon.tech](https://neon.tech) and create a free account
2. Create a new database
3. Copy the connection string (format: `postgresql://user:password@hostname/database`)

### 5. Configure Environment Variables

Create a `.env` file in the project root:

```bash
cp .env.example .env
```

Edit `.env` and add your credentials:

```env
# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here

# Database Configuration
DATABASE_URL=postgresql://user:password@your-neon-host.com/database

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True
SECRET_KEY=your-secret-key-here

# FAISS Configuration
FAISS_INDEX_PATH=./faiss_index.bin
FAISS_METADATA_PATH=./faiss_metadata.json
```

### 6. Initialize Database

Run the database initialization script:

```bash
python -c "from services.db_service import DatabaseService; db = DatabaseService(); db.initialize_database()"
```

Or manually run the SQL schema:

```bash
psql -h your-neon-host.com -U user -d database -f models/schema.sql
```

---

## â–¶ï¸ Running the Application

### Start the Flask Server

```bash
python app.py
```

The server will start on `http://localhost:5000`

### Access the Application

Open your browser and navigate to:
```
http://localhost:5000
```

---

## ğŸ¯ Usage

### Using the Chat Interface

1. **Select User**: Choose between Demo User (Beginner) or Advanced User from the dropdown
2. **Send Messages**: Type your question and press Enter or click Send
3. **View Context**: Each response shows detected intent, domain, and similar queries used
4. **Check Insights**: Click the "Insights" button to view conversation analytics

### Demo Users

The system comes with two pre-configured demo users:

**Demo User (ID: 1)**
- Expertise: Beginner
- Tone: Friendly
- Preferred Domains: Technology, Coding

**Advanced User (ID: 2)**
- Expertise: Advanced
- Tone: Professional
- Preferred Domains: Finance, Data Science

### API Endpoints

#### Chat
```http
POST /api/chat
Content-Type: application/json

{
  "message": "Explain blockchain",
  "user_id": 1
}
```

#### Get History
```http
GET /api/history/{user_id}?limit=20&offset=0
```

#### Get Insights
```http
GET /api/chat/insights/{user_id}
```

#### Get User
```http
GET /api/user/{user_id}
```

#### Health Check
```http
GET /api/health
```

---

## ğŸ“Š How Personalization Works

### Example: Original vs Enhanced Prompt

**Original User Message:**
```
"Explain blockchain"
```

**Enhanced Prompt Generated by PromptSense:**
```
[User Profile: beginner level, prefers friendly tone]
[Detected Domain: technology, Intent: learning]
[User previously asked similar questions: crypto basics, bitcoin explained]
[Recent conversation topics: technology, finance]
[Instructions: Explain concepts in simple terms with examples.
Use a warm, approachable tone. Focus on educational value and understanding]

User Query: Explain blockchain
```

**Result:** The LLM receives rich context and generates a beginner-friendly, example-rich explanation that matches the user's learning style.

---

## ğŸ”§ Configuration

### Customize User Preferences

Edit the database directly or modify `models/schema.sql`:

```sql
UPDATE users
SET preferences = '{
  "tone": "professional",
  "expertise_level": "advanced",
  "preferred_domains": ["science", "research"]
}'
WHERE id = 1;
```

### Adjust Similarity Search

Edit `config.py`:

```python
SIMILAR_QUERIES_LIMIT = 5  # Number of similar queries to find
EMBEDDING_DIMENSION = 3072  # OpenAI embedding dimension
```

---

## ğŸ“ Project Structure

```
promptsense/
â”‚
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables (create this)
â”œâ”€â”€ .env.example          # Environment template
â”œâ”€â”€ README.md             # This file
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schema.sql        # Database schema
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ db_service.py     # Database operations
â”‚   â”œâ”€â”€ openai_service.py # OpenAI API interactions
â”‚   â”œâ”€â”€ faiss_service.py  # Vector similarity search
â”‚   â””â”€â”€ prompt_engine.py  # Core personalization engine
â”‚
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ chat.py           # Chat endpoints
â”‚   â””â”€â”€ history.py        # History endpoints
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Main chat interface
â”‚
â””â”€â”€ static/
    â”œâ”€â”€ css/
    â”‚   â””â”€â”€ style.css     # Styling
    â””â”€â”€ js/
        â””â”€â”€ app.js        # Frontend JavaScript
```

---

## ğŸ§ª Testing

### Test the API with curl

```bash
# Health check
curl http://localhost:5000/api/health

# Send a message
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is machine learning?", "user_id": 1}'

# Get history
curl http://localhost:5000/api/history/1

# Get insights
curl http://localhost:5000/api/chat/insights/1
```

### Test with Python

```python
import requests

response = requests.post('http://localhost:5000/api/chat', json={
    'message': 'Explain neural networks',
    'user_id': 1
})

print(response.json())
```

---

## ğŸ“ Academic Context

### Research Problem
Generic prompts often lead to inconsistent or misaligned LLM responses. Users must manually craft detailed prompts to get quality results.

### Solution: PromptSense
Automatically enriches prompts with:
- User context and preferences
- Conversation history
- Similar past interactions
- Domain-specific instructions
- Intent-based guidance

### Key Technologies
- **Flask**: Web framework
- **OpenAI API**: LLM and embeddings
- **FAISS**: Vector similarity search
- **Postgres Neon**: Cloud database
- **Python**: Backend logic

### Metrics to Evaluate
- Response relevance score
- User satisfaction
- Query resolution rate
- Context utilization
- Similar query match rate

---

## ğŸ› Troubleshooting

### Database Connection Error
```
Error: Could not connect to database
```
**Solution**: Verify your `DATABASE_URL` in `.env` is correct and Neon database is accessible.

### OpenAI API Error
```
Error: Invalid API key
```
**Solution**: Check your `OPENAI_API_KEY` in `.env` file.

### FAISS Index Error
```
Error: Cannot load FAISS index
```
**Solution**: Delete `faiss_index.bin` and `faiss_metadata.json` to create fresh index.

### Module Not Found
```
ModuleNotFoundError: No module named 'flask'
```
**Solution**: Ensure virtual environment is activated and run `pip install -r requirements.txt`.

---

## ğŸš€ Deployment

### Deploy to Heroku

1. Create `Procfile`:
```
web: gunicorn app:app
```

2. Add gunicorn to requirements:
```bash
pip install gunicorn
pip freeze > requirements.txt
```

3. Deploy:
```bash
heroku create promptsense-app
git push heroku main
heroku config:set OPENAI_API_KEY=your-key
heroku config:set DATABASE_URL=your-neon-url
```

### Deploy to Railway

1. Connect GitHub repository
2. Add environment variables in Railway dashboard
3. Deploy automatically

---

## ğŸ“ Future Enhancements

- [ ] Multi-user authentication system
- [ ] Prompt template library
- [ ] A/B testing for prompt variations
- [ ] Export conversation history
- [ ] Admin dashboard
- [ ] Response quality feedback loop
- [ ] Multi-language support
- [ ] Voice input/output

---

## ğŸ“„ License

This project is created for academic purposes as part of a GenAI mini-project.

---

## ğŸ™ Acknowledgments

- OpenAI for GPT and embedding models
- Neon.tech for serverless Postgres
- FAISS by Meta AI for vector search
- Flask community

---

## ğŸ‘¨â€ğŸ’» Developer

Built for GenAI Subject Mini-Project
**Topic**: Context-Aware Prompt Personalization for Improved LLM Output Quality

---

## ğŸ“§ Support

For issues or questions, please create an issue in the repository or contact your course instructor.

---

**Happy Prompting! ğŸ¯**
